{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "# Context Engineering: LLMs for LF\n",
    "\n",
    "## Objective\n",
    "Generate Lingua Franca (LF) code from natural language prompt.\n",
    "\n",
    "## Context\n",
    "Large Language Models (LLMs) are a powerful tool for generating code. However, LLMs are often trained on standard programming languages like C/C++, Java, Python, and JavaScript. This makes it difficult to generate code in Domain-specific languages like Lingua Franca.\n",
    "\n",
    "This project shows how to curate context to guide the LLM.  We demonstrate the technique by showing how to generate code that uses the Lingua Franca coordination language together with C and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Environment Setup:\n",
    "- Virtual environment installation.\n",
    "- Necessary libraries installation.\n",
    "- Necessary imports.\n",
    "- OPEN_AI_API_KEY loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-24.2\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (1.35.13)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing Required Packages\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `.env` file is used to store sensitive information that you don't want to hard-code into your source code.\n",
    "\n",
    "\n",
    "For this project `OPENAI_API_KEY` is stored in `.env` file as:\n",
    "\n",
    "\n",
    "`OPENAI_API_KEY='your_openai_api_key'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading OPENAI_API_KEY from the .env file\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to estimate the probability that at least one of the top k samples is correct, \n",
    "given that there are c-correct samples in total out of n-generated samples.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "def pass_at_k(n, c, k): \n",
    "  \"\"\" \n",
    "  :param n: total number of samples \n",
    "  :param c: number of correct samples \n",
    "  :param k: k in pass@$k$ \n",
    "  \"\"\" \n",
    "  if n - c < k: \n",
    "    return 1.0 \n",
    "  return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Monte Carlo Estimation of π\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Prompting For regular Python code\n",
    "We start by prompting OpenAI's `gpt-4o` without any additional context.\n",
    "\n",
    "The generated code will be stored under `LFGPT/Python/pi`.\n",
    "\n",
    "We start by creating the target directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the target directory\n",
    "!mkdir -p LFGPT/Python/pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  A function to ganarate code.\n",
    "  Inputs:\n",
    "    file_name: name of the file to create\n",
    "    prompt: prompt to be used for generating code\n",
    "  Returns:\n",
    "    No value is returned.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def code_generator(file_name, prompt):\n",
    "  # Initializes an OpenAI client for interacting with the OpenAI API.\n",
    "  client = OpenAI()\n",
    "\n",
    "\n",
    "  MODEL = \"gpt-4o\"\n",
    "\n",
    "  fout = open(file_name, 'w')\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    temperature=0.8,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  print(completion.choices[0].message.content, file=fout)\n",
    "  fout.close()\n",
    "\n",
    "  print(file_name, \" sucessfully generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "fout = open(file_name, 'w')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "model=MODEL,\n",
    "temperature=0.8,\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt}\n",
    "]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Defining the prompt for a sequential execution\n",
    "prompt = f\"\"\" \n",
    "  Provide a python code to estimate PI through Monte Carlo Method with 10 million samples.\n",
    "  Provide code only, without any comment or code fences.\n",
    "  \"\"\"\n",
    "# File name suffix\n",
    "file_name = \"LFGPT/Python/pi/MonteCarlo\"\n",
    "\n",
    "# Defining run iterartor\n",
    "run_iterator = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFGPT/Python/pi/MonteCarlo_1.py  sucessfully generated.\n",
      "results:  3.1409356\n",
      "\n",
      "errors:  \n"
     ]
    }
   ],
   "source": [
    "run_iterator += 1\n",
    "# Name of the file to create\n",
    "f_name = f'{file_name}_{run_iterator}.py'\n",
    "# Generate code\n",
    "code_generator(f_name, prompt)\n",
    "\n",
    "import subprocess\n",
    "# Execute the code\n",
    "\n",
    "result = subprocess.run(['python3', f_name], capture_output=True, text=True)\n",
    "print(\"results: \", result.stdout)\n",
    "print(\"errors: \", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Prompting For parallel Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the prompt\n",
    "prompt = f\"\"\" \n",
    "  Provide a python code to estimate PI through Monte Carlo Method with 10 million samples.\n",
    "  The code should run in parallel and prints the number of processeses used.\n",
    "  Provide code only, without any comment or code fences.\n",
    "  \"\"\"\n",
    "# File name suffix\n",
    "file_name = \"LFGPT/Python/pi/ParallelMonteCarlo\"\n",
    "\n",
    "# Defining run iterartor\n",
    "run_iterator = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFGPT/Python/pi/ParallelMonteCarlo_5.py  sucessfully generated.\n",
      "results:  Estimated PI: 3.141682\n",
      "Number of processes used: 12\n",
      "\n",
      "errors:  \n"
     ]
    }
   ],
   "source": [
    "run_iterator += 1\n",
    "# Name of the file to create\n",
    "f_name = f'{file_name}_{run_iterator}.py'\n",
    "# Call code generator\n",
    "code_generator(f_name, prompt)\n",
    "# Run the generate file\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['python', f_name], capture_output=True, text=True)\n",
    "print(\"results: \", result.stdout)\n",
    "print(\"errors: \", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated PI: 3.1416552\n",
      "Number of processes used: 12\n"
     ]
    }
   ],
   "source": [
    "!python LFGPT/Python/pi/ParallelMonteCarlo_1.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Prompting For sequential LF code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 Prompting Without context\n",
    "We start by prompting OpenAI's `gpt-4o` without any additional context.\n",
    "\n",
    "The generated code will be stored under `LFGPT/without_context/pi`.\n",
    "\n",
    "We start by creating the target directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the target directory\n",
    "!mkdir -p LFGPT/without_context/pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Defining the prompt\n",
    "prompt = f\"\"\" \n",
    "  Provide a Lingua Franca code for 'target Python'. \n",
    "  Create a main reactor named `MonteCarlo` that:\n",
    "  - has no outputs.\n",
    "  - has a parameter named `num_samples`, with a default value of 10 millions.\n",
    "  - estimates PI through Monte Carlo Method with `num_samples`.\n",
    "  - prints the estimated value of PI to the console.\n",
    "\n",
    "  Provide code only, without any comment or code fences.\n",
    "  \"\"\"\n",
    "# File name suffix\n",
    "file_name = \"LFGPT/without_context/pi/MonteCarlo\"\n",
    "\n",
    "# Defining run iterartor\n",
    "run_iterator = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def run_xp(file_name, prompt, generator, samples):\n",
    "    errors = \" ----------  Compile errors ------------\\n\"\n",
    "    exec_errors = \" ----------  Exeecution errors ------------\\n\"\n",
    "\n",
    "    xp = {\n",
    "        \"compile_sucess\": 0,\n",
    "        \"compile_error\": 0,\n",
    "        \"run_sucess\": 0,\n",
    "        \"run_error\": 0\n",
    "    }\n",
    "\n",
    "    for run_iterator in range(samples):\n",
    "        # Name of the file to create\n",
    "        f_name = f'{file_name}_{run_iterator}.lf'\n",
    "        # Generate code \n",
    "        generator(f_name, prompt)\n",
    "\n",
    "        # Copy the generated file into a file that matches the main reactor name.\n",
    "        shutil.copy(f_name, f'{file_name}.lf')\n",
    "\n",
    "        \n",
    "        # Compile the generated LF file\n",
    "        result = subprocess.run(['lfc', f'{file_name}.lf'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            xp['compile_sucess'] += 1\n",
    "            # Run the generated Python code\n",
    "            executable = 'src-gen/' + file_name + \"/\" +file_name.split('/')[-1] + '.py'\n",
    "            exec_result = subprocess.run(['python3', executable], capture_output=True, text=True)\n",
    "            if exec_result.returncode == 0:\n",
    "                xp['run_sucess'] += 1\n",
    "            else:\n",
    "                xp['run_error'] += 1\n",
    "                exec_errors += exec_result.stderr\n",
    "        else:\n",
    "            xp['compile_error'] += 1\n",
    "            errors += result.stderr\n",
    "            \n",
    "    print(f'Compile success: {xp[\"compile_sucess\"]}')\n",
    "\n",
    "    print(f'Run success: {xp[\"run_sucess\"]}')\n",
    "\n",
    "\n",
    "    print(errors, file=open(file_name + \"_compile_errors.txt\", 'w', encoding='utf-8'))\n",
    "    print(exec_errors, file=open(file_name + \"_exec_errors.txt\", 'w', encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFGPT/without_context/pi/MonteCarlo_0.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_1.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_2.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_3.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_4.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_5.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_6.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_7.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_8.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_9.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_10.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_11.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_12.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_13.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_14.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_15.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_16.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_17.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_18.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_19.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_20.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_21.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_22.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_23.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_24.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_25.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_26.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_27.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_28.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_29.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_30.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_31.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_32.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_33.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_34.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_35.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_36.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_37.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_38.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_39.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_40.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_41.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_42.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_43.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_44.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_45.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_46.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_47.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_48.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_49.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_50.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_51.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_52.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_53.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_54.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_55.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_56.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_57.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_58.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_59.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_60.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_61.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_62.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_63.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_64.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_65.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_66.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_67.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_68.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_69.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_70.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_71.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_72.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_73.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_74.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_75.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_76.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_77.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_78.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_79.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_80.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_81.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_82.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_83.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_84.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_85.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_86.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_87.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_88.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_89.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_90.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_91.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_92.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_93.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_94.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_95.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_96.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_97.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_98.lf  sucessfully generated.\n",
      "LFGPT/without_context/pi/MonteCarlo_99.lf  sucessfully generated.\n",
      "Compile success: 0\n",
      "Run success: 0\n"
     ]
    }
   ],
   "source": [
    "run_xp(file_name, prompt, code_generator, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 Prompting with RAG\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import os \n",
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex\n",
    "    \n",
    ")\n",
    "\n",
    "# Setting codebase directory\n",
    "# contains examples directory from https://github.com/lf-lang/playground-lingua-franca\n",
    "DIR = \"./python_codebase\"\n",
    "\n",
    "# Setting storage directory\n",
    "PERSIST_DIR = \"./index_python_codebase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating indexes from scratch ...\n"
     ]
    }
   ],
   "source": [
    "# If `VectorStoreIndex` exists load it from disk.\n",
    "# Else, Build it from code_base and save it to disk, for future use.\n",
    "\n",
    "def load_storage_context():\n",
    "    # if 'PERSIST_DIR' exists, load indexes from persisted data\n",
    "    # else load create indexes from code base dierctory, 'data'.\n",
    "    if (os.path.exists(PERSIST_DIR)):\n",
    "        # load the existing index\n",
    "        print(\"Loading persisted indexes ...\")\n",
    "        # rebuild storage context\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "        return storage_context      \n",
    "    else:\n",
    "        print(\"Creating indexes from scratch ...\")\n",
    "        # load documents from directory\n",
    "        documents = SimpleDirectoryReader(DIR, recursive=True).load_data()\n",
    "\n",
    "        # build index with embedding model \"gpt-4o\"\n",
    "        index = VectorStoreIndex.from_documents(documents, model=\"gpt-4o\")\n",
    "\n",
    "        # save indexes on disk\n",
    "        index.storage_context.persist(persist_dir=PERSIST_DIR) \n",
    "        return index.storage_context\n",
    "\n",
    "# Loading `VectorStoreIndex` (storage context) from disk\n",
    "storage_context = load_storage_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the target directory\n",
    "!mkdir -p LFGPT/rag/pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Define LLM to use for Code geneartion\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "# Define the Top K retrived documents (LF files)\n",
    "TOP_K = 10\n",
    "\n",
    "# Instatntiate the LLM\n",
    "llm = OpenAI(temperature=0.8, model=MODEL)\n",
    "\n",
    "# Instantiate a ServiceContext using the OpenAI_API_key\n",
    "index = load_index_from_storage(storage_context, llm=llm)        \n",
    " \n",
    "# Configure retriever\n",
    "query_engine = index.as_query_engine(similarity_top_k=TOP_K)\n",
    "\n",
    "\n",
    "\n",
    "# Defining run iterartor\n",
    "run_iterator = 0\n",
    "\n",
    "# File name suffix\n",
    "file_name = \"LFGPT/rag/pi/MonteCarlo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag(file_name, prompt):    \n",
    "    response = query_engine.query(prompt)\n",
    "    files = '/**\\n'\n",
    "    for node in response.source_nodes:\n",
    "        files += f'* {node.metadata[\"file_path\"]}\\n'\n",
    "    files += '*/\\n'\n",
    "\n",
    "    fout = open(file_name, 'w')\n",
    "\n",
    "    print(files+response.response, file=fout)\n",
    "    fout.close()\n",
    "\n",
    "    print(file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering\n",
    "- imports are not embedded in a preamble. Add:\n",
    "```embed imports in a preamble.```\n",
    "- The generated code has no `reaction`. The Python code needs to be inside a reaction. Explicitly instruct the LLM to use a reaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the prompt\n",
    "prompt = f\"\"\" \n",
    "  Provide a Lingua Franca code for 'target Python'. \n",
    "  imports the random module.\n",
    "  Create a main reactor named `MonteCarlo` that:\n",
    "  - has no outputs.\n",
    "  - has a reaction that triggers at startup.\n",
    "  - the reaction estimates PI through Monte Carlo Method with  10 million samples.\n",
    "  - prints the estimated value of PI to the console.\n",
    "  - embed imports in a preamble.\n",
    "\n",
    "\n",
    "  Provide code only, without any comment or code fences.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFGPT/rag/pi/MonteCarlo_0.lf\n",
      "LFGPT/rag/pi/MonteCarlo_1.lf\n",
      "LFGPT/rag/pi/MonteCarlo_2.lf\n",
      "LFGPT/rag/pi/MonteCarlo_3.lf\n",
      "LFGPT/rag/pi/MonteCarlo_4.lf\n",
      "LFGPT/rag/pi/MonteCarlo_5.lf\n",
      "LFGPT/rag/pi/MonteCarlo_6.lf\n",
      "LFGPT/rag/pi/MonteCarlo_7.lf\n",
      "LFGPT/rag/pi/MonteCarlo_8.lf\n",
      "LFGPT/rag/pi/MonteCarlo_9.lf\n",
      "LFGPT/rag/pi/MonteCarlo_10.lf\n",
      "LFGPT/rag/pi/MonteCarlo_11.lf\n",
      "LFGPT/rag/pi/MonteCarlo_12.lf\n",
      "LFGPT/rag/pi/MonteCarlo_13.lf\n",
      "LFGPT/rag/pi/MonteCarlo_14.lf\n",
      "LFGPT/rag/pi/MonteCarlo_15.lf\n",
      "LFGPT/rag/pi/MonteCarlo_16.lf\n",
      "LFGPT/rag/pi/MonteCarlo_17.lf\n",
      "LFGPT/rag/pi/MonteCarlo_18.lf\n",
      "LFGPT/rag/pi/MonteCarlo_19.lf\n",
      "LFGPT/rag/pi/MonteCarlo_20.lf\n",
      "LFGPT/rag/pi/MonteCarlo_21.lf\n",
      "LFGPT/rag/pi/MonteCarlo_22.lf\n",
      "LFGPT/rag/pi/MonteCarlo_23.lf\n",
      "LFGPT/rag/pi/MonteCarlo_24.lf\n",
      "LFGPT/rag/pi/MonteCarlo_25.lf\n",
      "LFGPT/rag/pi/MonteCarlo_26.lf\n",
      "LFGPT/rag/pi/MonteCarlo_27.lf\n",
      "LFGPT/rag/pi/MonteCarlo_28.lf\n",
      "LFGPT/rag/pi/MonteCarlo_29.lf\n",
      "LFGPT/rag/pi/MonteCarlo_30.lf\n",
      "LFGPT/rag/pi/MonteCarlo_31.lf\n",
      "LFGPT/rag/pi/MonteCarlo_32.lf\n",
      "LFGPT/rag/pi/MonteCarlo_33.lf\n",
      "LFGPT/rag/pi/MonteCarlo_34.lf\n",
      "LFGPT/rag/pi/MonteCarlo_35.lf\n",
      "LFGPT/rag/pi/MonteCarlo_36.lf\n",
      "LFGPT/rag/pi/MonteCarlo_37.lf\n",
      "LFGPT/rag/pi/MonteCarlo_38.lf\n",
      "LFGPT/rag/pi/MonteCarlo_39.lf\n",
      "LFGPT/rag/pi/MonteCarlo_40.lf\n",
      "LFGPT/rag/pi/MonteCarlo_41.lf\n",
      "LFGPT/rag/pi/MonteCarlo_42.lf\n",
      "LFGPT/rag/pi/MonteCarlo_43.lf\n",
      "LFGPT/rag/pi/MonteCarlo_44.lf\n",
      "LFGPT/rag/pi/MonteCarlo_45.lf\n",
      "LFGPT/rag/pi/MonteCarlo_46.lf\n",
      "LFGPT/rag/pi/MonteCarlo_47.lf\n",
      "LFGPT/rag/pi/MonteCarlo_48.lf\n",
      "LFGPT/rag/pi/MonteCarlo_49.lf\n",
      "LFGPT/rag/pi/MonteCarlo_50.lf\n",
      "LFGPT/rag/pi/MonteCarlo_51.lf\n",
      "LFGPT/rag/pi/MonteCarlo_52.lf\n",
      "LFGPT/rag/pi/MonteCarlo_53.lf\n",
      "LFGPT/rag/pi/MonteCarlo_54.lf\n",
      "LFGPT/rag/pi/MonteCarlo_55.lf\n",
      "LFGPT/rag/pi/MonteCarlo_56.lf\n",
      "LFGPT/rag/pi/MonteCarlo_57.lf\n",
      "LFGPT/rag/pi/MonteCarlo_58.lf\n",
      "LFGPT/rag/pi/MonteCarlo_59.lf\n",
      "LFGPT/rag/pi/MonteCarlo_60.lf\n",
      "LFGPT/rag/pi/MonteCarlo_61.lf\n",
      "LFGPT/rag/pi/MonteCarlo_62.lf\n",
      "LFGPT/rag/pi/MonteCarlo_63.lf\n",
      "LFGPT/rag/pi/MonteCarlo_64.lf\n",
      "LFGPT/rag/pi/MonteCarlo_65.lf\n",
      "LFGPT/rag/pi/MonteCarlo_66.lf\n",
      "LFGPT/rag/pi/MonteCarlo_67.lf\n",
      "LFGPT/rag/pi/MonteCarlo_68.lf\n",
      "LFGPT/rag/pi/MonteCarlo_69.lf\n",
      "LFGPT/rag/pi/MonteCarlo_70.lf\n",
      "LFGPT/rag/pi/MonteCarlo_71.lf\n",
      "LFGPT/rag/pi/MonteCarlo_72.lf\n",
      "LFGPT/rag/pi/MonteCarlo_73.lf\n",
      "LFGPT/rag/pi/MonteCarlo_74.lf\n",
      "LFGPT/rag/pi/MonteCarlo_75.lf\n",
      "LFGPT/rag/pi/MonteCarlo_76.lf\n",
      "LFGPT/rag/pi/MonteCarlo_77.lf\n",
      "LFGPT/rag/pi/MonteCarlo_78.lf\n",
      "LFGPT/rag/pi/MonteCarlo_79.lf\n",
      "LFGPT/rag/pi/MonteCarlo_80.lf\n",
      "LFGPT/rag/pi/MonteCarlo_81.lf\n",
      "LFGPT/rag/pi/MonteCarlo_82.lf\n",
      "LFGPT/rag/pi/MonteCarlo_83.lf\n",
      "LFGPT/rag/pi/MonteCarlo_84.lf\n",
      "LFGPT/rag/pi/MonteCarlo_85.lf\n",
      "LFGPT/rag/pi/MonteCarlo_86.lf\n",
      "LFGPT/rag/pi/MonteCarlo_87.lf\n",
      "LFGPT/rag/pi/MonteCarlo_88.lf\n",
      "LFGPT/rag/pi/MonteCarlo_89.lf\n",
      "LFGPT/rag/pi/MonteCarlo_90.lf\n",
      "LFGPT/rag/pi/MonteCarlo_91.lf\n",
      "LFGPT/rag/pi/MonteCarlo_92.lf\n",
      "LFGPT/rag/pi/MonteCarlo_93.lf\n",
      "LFGPT/rag/pi/MonteCarlo_94.lf\n",
      "LFGPT/rag/pi/MonteCarlo_95.lf\n",
      "LFGPT/rag/pi/MonteCarlo_96.lf\n",
      "LFGPT/rag/pi/MonteCarlo_97.lf\n",
      "LFGPT/rag/pi/MonteCarlo_98.lf\n",
      "LFGPT/rag/pi/MonteCarlo_99.lf\n",
      "Compile success: 93\n",
      "Run success: 93\n"
     ]
    }
   ],
   "source": [
    "run_xp(file_name, prompt, rag, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "On 100 experiments (generated LF files), the AI was able to predict the correct LF code 93 times out of 100.\n",
    "\n",
    "Compile success: 93\n",
    "\n",
    "Run success: 93\n",
    "\n",
    "The `pass@k` metric is defined as the probability that at least one of the top k-generated code samples for a problem passes the unit tests. This approach is inspired by the practices of human developers, who judge the correctness of code based on whether it passes a set of unit tests.\n",
    "\n",
    "The folling is `pass@k` computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass@1:  0.93\n",
      "pass@2:  0.9958\n",
      "pass@5:  1.0\n",
      "pass@10:  1.0\n"
     ]
    }
   ],
   "source": [
    "for K in [1,2,5,10]:\n",
    "    print(f\"pass@{K}: \", round(pass_at_k(100, 93, K),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lfc LFGPT/rag/pi/MonteCarlo.lf\n",
    "!python src-gen/LFGPT/rag/pi/MonteCarlo/MonteCarlo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting For parallel LF code (Python target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the prompt\n",
    "prompt = f\"\"\" \n",
    "  Provide a Lingua Franca code for 'target Python'. \n",
    "  Use a preamble to include imports.\n",
    "  Create a reactor named `MonteCarlo` that:\n",
    "  - has one output port named `out` of type `float`.\n",
    "  - has a reaction that triggers at startup.\n",
    "  - the reaction estimates PI through Monte Carlo Method with forth of 10 million samples.\n",
    "  - sets the output to the estimated value of PI.\n",
    "\n",
    "  Create a federated reactor named `ParallelMonteCarlo` that:\n",
    "  - instantiates 4 reactors named `MonteCarlo` in parallel.\n",
    "  - sum the outputs of the 4 reactors and prints the result.\n",
    "\n",
    "  Provide code only, without any comment or code fences.\n",
    "  \"\"\"\n",
    "\n",
    "# File name suffix\n",
    "file_name = \"LFGPT/rag/pi/ParallelMonteCarlo\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFGPT/rag/pi/ParallelMonteCarlo_0.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_1.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_2.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_3.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_4.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_5.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_6.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_7.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_8.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_9.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_10.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_11.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_12.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_13.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_14.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_15.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_16.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_17.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_18.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_19.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_20.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_21.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_22.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_23.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_24.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_25.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_26.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_27.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_28.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_29.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_30.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_31.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_32.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_33.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_34.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_35.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_36.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_37.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_38.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_39.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_40.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_41.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_42.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_43.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_44.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_45.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_46.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_47.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_48.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_49.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_50.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_51.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_52.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_53.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_54.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_55.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_56.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_57.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_58.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_59.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_60.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_61.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_62.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_63.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_64.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_65.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_66.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_67.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_68.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_69.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_70.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_71.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_72.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_73.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_74.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_75.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_76.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_77.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_78.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_79.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_80.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_81.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_82.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_83.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_84.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_85.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_86.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_87.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_88.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_89.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_90.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_91.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_92.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_93.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_94.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_95.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_96.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_97.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_98.lf\n",
      "LFGPT/rag/pi/ParallelMonteCarlo_99.lf\n",
      "Compile success: 0\n",
      "Run success: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_xp(file_name, prompt, rag, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfc: \u001b[1;33mwarning\u001b[0m\u001b[1m: File 'ParallelMonteCarlo.lf' is not located in an 'src' directory.\u001b[0m\n",
      "lfc: \u001b[1;33mwarning\u001b[0m\u001b[1m: Adopting the current working directory as the package root.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: ##### Generating code for federate federate__m1 in directory /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: ##### Generating code for federate federate__m2 in directory /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: ##### Generating code for federate federate__m3 in directory /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: ##### Generating code for federate federate__m4 in directory /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: ******** Using 1 threads to compile the program.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating code for: file:/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src/federate__m1.lf\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generation mode: STANDALONE\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating sources into: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m1\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Target Configuration:\n",
      "      - _fed_setup: include/_federate__m1_preamble.h\n",
      "      - keepalive: true\n",
      "      - single-threaded: false\n",
      "      - compile-definitions: {EXECUTABLE_PREAMBLE=, FEDERATED=, FEDERATED_CENTRALIZED=, NUMBER_OF_FEDERATES=4}\n",
      "      - compiler: gcc\n",
      "      - docker: DockerOptions[enabled=false, from=, rti=lflang/rti:rti]\u001b[0m\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/include/src/federate__m1\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m1/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m1/build\n",
      "--- Executing command: cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo -DCMAKE_INSTALL_BINDIR=bin -DLF_FILE_SEPARATOR=\"/\" /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m1\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/gcc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Including sources for threaded runtime with 0 worker(s) with scheduler=SCHED_NP and tracing=.\n",
      "-- Including the following sources: tag.c, port.c, mixed_radix.c, reactor_common.c, lf_token.c, environment.c, clock-sync.c, federate.c, net_util.c, reactor_threaded.c, scheduler_adaptive.c, scheduler_GEDF_NP.c, scheduler_NP.c, scheduler_sync_tag_advance.c, scheduler_instance.c, watchdog.c, vector.c, pqueue_base.c, pqueue_tag.c, pqueue.c, util.c, semaphore.c, hashset.c, hashset_itr.c, modes.c, lf_unix_clock_support.c, lf_unix_syscall_support.c, lf_linux_support.c, lf_macos_support.c, lf_windows_support.c, lf_nrf52_support.c, lf_zephyr_support.c, lf_zephyr_clock_counter.c, lf_zephyr_clock_kernel.c, lf_rp2040_support.c\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Applying preprocessor definitions...\n",
      "-- EXECUTABLE_PREAMBLE=TRUE\n",
      "-- FEDERATED_CENTRALIZED=TRUE\n",
      "-- FEDERATED=TRUE\n",
      "-- LF_REACTION_GRAPH_BREADTH=2\n",
      "-- LOG_LEVEL=2\n",
      "-- NUMBER_OF_FEDERATES=4\n",
      "-- NUMBER_OF_WORKERS=0\n",
      "-- SCHEDULER=SCHED_NP\n",
      "-- LF_FILE_SEPARATOR=\"/\"\n",
      "-- Found Python: /home/moez/AccountableAI/LFGPT/lf-gpt/.venv/bin/python3.10 (found suitable version \"3.10.12\", required range is \"3.10.0...<3.11.0\") found components: Interpreter Development Development.Module Development.Embed \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/moez/AccountableAI/LFGPT/lf-gpt/fed-gen/ParallelMonteCarlo/src-gen/federate__m1/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m1/build\n",
      "--- Executing command: cmake --build . --target install --parallel 12 --config Debug\n",
      "[  2%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/tag.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/port.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/mixed_radix.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/lf_token.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/environment.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/clock-sync.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/reactor_common.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/federate.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/network/net_util.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/reactor_threaded.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_adaptive.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_GEDF_NP.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_NP.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_sync_tag_advance.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_instance.c.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/vector.c.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/watchdog.c.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_base.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_tag.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue.c.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/semaphore.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/util.c.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset_itr.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset.c.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/modal_models/modes.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_clock_support.c.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_syscall_support.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_linux_support.c.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_windows_support.c.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_macos_support.c.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_nrf52_support.c.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_support.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_counter.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_kernel.c.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_rp2040_support.c.o\u001b[0m\n",
      "[ 78%] \u001b[32m\u001b[1mLinking C static library libcore.a\u001b[0m\n",
      "[ 78%] Built target core\n",
      "[ 80%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/python_tag.c.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/python_port.c.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/python_action.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/_federate__m1_main.c.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/_montecarlo.c.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/python_time.c.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/pythontarget.c.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/federate__m1.c.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m1.dir/lib/schedule.c.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking C shared module ../LinguaFrancafederate__m1.so\u001b[0m\n",
      "[100%] Built target LinguaFrancafederate__m1\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: SUCCESS: Compiling generated code for federate__m1 finished with no errors.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Compiled binary is in /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/bin\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating code for: file:/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src/federate__m2.lf\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generation mode: STANDALONE\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating sources into: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m2\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Target Configuration:\n",
      "      - _fed_setup: include/_federate__m2_preamble.h\n",
      "      - keepalive: true\n",
      "      - single-threaded: false\n",
      "      - compile-definitions: {EXECUTABLE_PREAMBLE=, FEDERATED=, FEDERATED_CENTRALIZED=, NUMBER_OF_FEDERATES=4}\n",
      "      - compiler: gcc\n",
      "      - docker: DockerOptions[enabled=false, from=, rti=lflang/rti:rti]\u001b[0m\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/include/src/federate__m2\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m2/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m2/build\n",
      "--- Executing command: cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo -DCMAKE_INSTALL_BINDIR=bin -DLF_FILE_SEPARATOR=\"/\" /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m2\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/gcc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Including sources for threaded runtime with 0 worker(s) with scheduler=SCHED_NP and tracing=.\n",
      "-- Including the following sources: tag.c, port.c, mixed_radix.c, reactor_common.c, lf_token.c, environment.c, clock-sync.c, federate.c, net_util.c, reactor_threaded.c, scheduler_adaptive.c, scheduler_GEDF_NP.c, scheduler_NP.c, scheduler_sync_tag_advance.c, scheduler_instance.c, watchdog.c, vector.c, pqueue_base.c, pqueue_tag.c, pqueue.c, util.c, semaphore.c, hashset.c, hashset_itr.c, modes.c, lf_unix_clock_support.c, lf_unix_syscall_support.c, lf_linux_support.c, lf_macos_support.c, lf_windows_support.c, lf_nrf52_support.c, lf_zephyr_support.c, lf_zephyr_clock_counter.c, lf_zephyr_clock_kernel.c, lf_rp2040_support.c\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Applying preprocessor definitions...\n",
      "-- EXECUTABLE_PREAMBLE=TRUE\n",
      "-- FEDERATED_CENTRALIZED=TRUE\n",
      "-- FEDERATED=TRUE\n",
      "-- LF_REACTION_GRAPH_BREADTH=1\n",
      "-- LOG_LEVEL=2\n",
      "-- NUMBER_OF_FEDERATES=4\n",
      "-- NUMBER_OF_WORKERS=0\n",
      "-- SCHEDULER=SCHED_NP\n",
      "-- LF_FILE_SEPARATOR=\"/\"\n",
      "-- Found Python: /home/moez/AccountableAI/LFGPT/lf-gpt/.venv/bin/python3.10 (found suitable version \"3.10.12\", required range is \"3.10.0...<3.11.0\") found components: Interpreter Development Development.Module Development.Embed \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/moez/AccountableAI/LFGPT/lf-gpt/fed-gen/ParallelMonteCarlo/src-gen/federate__m2/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m2/build\n",
      "--- Executing command: cmake --build . --target install --parallel 12 --config Debug\n",
      "[  6%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/mixed_radix.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/tag.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/reactor_common.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/lf_token.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/clock-sync.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/federate.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/environment.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/network/net_util.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/port.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_adaptive.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_GEDF_NP.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/reactor_threaded.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_NP.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_sync_tag_advance.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/watchdog.c.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_instance.c.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/vector.c.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_base.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_tag.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue.c.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/util.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/semaphore.c.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset_itr.c.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_clock_support.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_syscall_support.c.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/modal_models/modes.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_linux_support.c.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_support.c.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_macos_support.c.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_windows_support.c.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_nrf52_support.c.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_counter.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_kernel.c.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_rp2040_support.c.o\u001b[0m\n",
      "[ 78%] \u001b[32m\u001b[1mLinking C static library libcore.a\u001b[0m\n",
      "[ 78%] Built target core\n",
      "[ 80%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/python_tag.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/python_action.c.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/schedule.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/python_port.c.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/python_time.c.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/_montecarlo.c.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/_federate__m2_main.c.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/lib/pythontarget.c.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m2.dir/federate__m2.c.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking C shared module ../LinguaFrancafederate__m2.so\u001b[0m\n",
      "[100%] Built target LinguaFrancafederate__m2\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: SUCCESS: Compiling generated code for federate__m2 finished with no errors.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Compiled binary is in /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/bin\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating code for: file:/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src/federate__m3.lf\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generation mode: STANDALONE\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating sources into: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m3\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Target Configuration:\n",
      "      - _fed_setup: include/_federate__m3_preamble.h\n",
      "      - keepalive: true\n",
      "      - single-threaded: false\n",
      "      - compile-definitions: {EXECUTABLE_PREAMBLE=, FEDERATED=, FEDERATED_CENTRALIZED=, NUMBER_OF_FEDERATES=4}\n",
      "      - compiler: gcc\n",
      "      - docker: DockerOptions[enabled=false, from=, rti=lflang/rti:rti]\u001b[0m\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/include/src/federate__m3\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m3/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m3/build\n",
      "--- Executing command: cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo -DCMAKE_INSTALL_BINDIR=bin -DLF_FILE_SEPARATOR=\"/\" /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m3\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/gcc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Including sources for threaded runtime with 0 worker(s) with scheduler=SCHED_NP and tracing=.\n",
      "-- Including the following sources: tag.c, port.c, mixed_radix.c, reactor_common.c, lf_token.c, environment.c, clock-sync.c, federate.c, net_util.c, reactor_threaded.c, scheduler_adaptive.c, scheduler_GEDF_NP.c, scheduler_NP.c, scheduler_sync_tag_advance.c, scheduler_instance.c, watchdog.c, vector.c, pqueue_base.c, pqueue_tag.c, pqueue.c, util.c, semaphore.c, hashset.c, hashset_itr.c, modes.c, lf_unix_clock_support.c, lf_unix_syscall_support.c, lf_linux_support.c, lf_macos_support.c, lf_windows_support.c, lf_nrf52_support.c, lf_zephyr_support.c, lf_zephyr_clock_counter.c, lf_zephyr_clock_kernel.c, lf_rp2040_support.c\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Applying preprocessor definitions...\n",
      "-- EXECUTABLE_PREAMBLE=TRUE\n",
      "-- FEDERATED_CENTRALIZED=TRUE\n",
      "-- FEDERATED=TRUE\n",
      "-- LF_REACTION_GRAPH_BREADTH=1\n",
      "-- LOG_LEVEL=2\n",
      "-- NUMBER_OF_FEDERATES=4\n",
      "-- NUMBER_OF_WORKERS=0\n",
      "-- SCHEDULER=SCHED_NP\n",
      "-- LF_FILE_SEPARATOR=\"/\"\n",
      "-- Found Python: /home/moez/AccountableAI/LFGPT/lf-gpt/.venv/bin/python3.10 (found suitable version \"3.10.12\", required range is \"3.10.0...<3.11.0\") found components: Interpreter Development Development.Module Development.Embed \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/moez/AccountableAI/LFGPT/lf-gpt/fed-gen/ParallelMonteCarlo/src-gen/federate__m3/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m3/build\n",
      "--- Executing command: cmake --build . --target install --parallel 12 --config Debug\n",
      "[  2%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/tag.c.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/port.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/reactor_common.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/environment.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/mixed_radix.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/lf_token.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/network/net_util.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/federate.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/clock-sync.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/reactor_threaded.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_adaptive.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_GEDF_NP.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_NP.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_sync_tag_advance.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_instance.c.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/vector.c.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_base.c.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_tag.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/watchdog.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/util.c.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/semaphore.c.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/modal_models/modes.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_syscall_support.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset_itr.c.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_linux_support.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_clock_support.c.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_macos_support.c.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_windows_support.c.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_nrf52_support.c.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_support.c.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_kernel.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_counter.c.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_rp2040_support.c.o\u001b[0m\n",
      "[ 78%] \u001b[32m\u001b[1mLinking C static library libcore.a\u001b[0m\n",
      "[ 78%] Built target core\n",
      "[ 80%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/schedule.c.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/python_time.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/python_action.c.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/_federate__m3_main.c.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/python_port.c.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/python_tag.c.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/lib/pythontarget.c.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/federate__m3.c.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m3.dir/_montecarlo.c.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking C shared module ../LinguaFrancafederate__m3.so\u001b[0m\n",
      "[100%] Built target LinguaFrancafederate__m3\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: SUCCESS: Compiling generated code for federate__m3 finished with no errors.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Compiled binary is in /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/bin\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating code for: file:/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src/federate__m4.lf\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generation mode: STANDALONE\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Generating sources into: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m4\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Target Configuration:\n",
      "      - _fed_setup: include/_federate__m4_preamble.h\n",
      "      - keepalive: true\n",
      "      - single-threaded: false\n",
      "      - compile-definitions: {EXECUTABLE_PREAMBLE=, FEDERATED=, FEDERATED_CENTRALIZED=, NUMBER_OF_FEDERATES=4}\n",
      "      - compiler: gcc\n",
      "      - docker: DockerOptions[enabled=false, from=, rti=lflang/rti:rti]\u001b[0m\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/include/src/federate__m4\n",
      "Cleaning /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m4/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m4/build\n",
      "--- Executing command: cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo -DCMAKE_INSTALL_BINDIR=bin -DLF_FILE_SEPARATOR=\"/\" /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m4\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/gcc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Including sources for threaded runtime with 0 worker(s) with scheduler=SCHED_NP and tracing=.\n",
      "-- Including the following sources: tag.c, port.c, mixed_radix.c, reactor_common.c, lf_token.c, environment.c, clock-sync.c, federate.c, net_util.c, reactor_threaded.c, scheduler_adaptive.c, scheduler_GEDF_NP.c, scheduler_NP.c, scheduler_sync_tag_advance.c, scheduler_instance.c, watchdog.c, vector.c, pqueue_base.c, pqueue_tag.c, pqueue.c, util.c, semaphore.c, hashset.c, hashset_itr.c, modes.c, lf_unix_clock_support.c, lf_unix_syscall_support.c, lf_linux_support.c, lf_macos_support.c, lf_windows_support.c, lf_nrf52_support.c, lf_zephyr_support.c, lf_zephyr_clock_counter.c, lf_zephyr_clock_kernel.c, lf_rp2040_support.c\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Applying preprocessor definitions...\n",
      "-- EXECUTABLE_PREAMBLE=TRUE\n",
      "-- FEDERATED_CENTRALIZED=TRUE\n",
      "-- FEDERATED=TRUE\n",
      "-- LF_REACTION_GRAPH_BREADTH=1\n",
      "-- LOG_LEVEL=2\n",
      "-- NUMBER_OF_FEDERATES=4\n",
      "-- NUMBER_OF_WORKERS=0\n",
      "-- SCHEDULER=SCHED_NP\n",
      "-- LF_FILE_SEPARATOR=\"/\"\n",
      "-- Found Python: /home/moez/AccountableAI/LFGPT/lf-gpt/.venv/bin/python3.10 (found suitable version \"3.10.12\", required range is \"3.10.0...<3.11.0\") found components: Interpreter Development Development.Module Development.Embed \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/moez/AccountableAI/LFGPT/lf-gpt/fed-gen/ParallelMonteCarlo/src-gen/federate__m4/build\n",
      "--- Current working directory: /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/src-gen/federate__m4/build\n",
      "--- Executing command: cmake --build . --target install --parallel 12 --config Debug\n",
      "[  2%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/mixed_radix.c.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/tag.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/port.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/lf_token.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/reactor_common.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/network/net_util.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/federate.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/reactor_threaded.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/environment.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/federated/clock-sync.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_adaptive.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_GEDF_NP.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_NP.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_sync_tag_advance.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/scheduler_instance.c.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/threaded/watchdog.c.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/vector.c.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_base.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue_tag.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/pqueue.c.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/util.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/semaphore.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset_itr.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/utils/hashset/hashset.c.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/modal_models/modes.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_clock_support.c.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_unix_syscall_support.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_linux_support.c.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_macos_support.c.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_windows_support.c.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_nrf52_support.c.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_rp2040_support.c.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_kernel.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_clock_counter.c.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding C object core/CMakeFiles/core.dir/platform/lf_zephyr_support.c.o\u001b[0m\n",
      "[ 78%] \u001b[32m\u001b[1mLinking C static library libcore.a\u001b[0m\n",
      "[ 78%] Built target core\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/python_port.c.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/python_tag.c.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/schedule.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/python_action.c.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/federate__m4.c.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/pythontarget.c.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/_federate__m4_main.c.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/lib/python_time.c.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding C object CMakeFiles/LinguaFrancafederate__m4.dir/_montecarlo.c.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking C shared module ../LinguaFrancafederate__m4.so\u001b[0m\n",
      "[100%] Built target LinguaFrancafederate__m4\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: SUCCESS: Compiling generated code for federate__m4 finished with no errors.\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Compiled binary is in /home/moez/AccountableAI/LFGPT/lf-gpt/./fed-gen/ParallelMonteCarlo/bin\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Script for launching the federation: /home/moez/AccountableAI/LFGPT/lf-gpt/bin/ParallelMonteCarlo\u001b[0m\n",
      "lfc: \u001b[1minfo\u001b[0m\u001b[1m: Code generation finished.\u001b[0m\n",
      "---- System clock resolution: 1 nsec\n",
      "---- Start execution at time Thu Aug  1 12:55:02 2024\n",
      "---- plus 572221062 nanoseconds\n",
      "Environment 0: ---- Intializing start tag\n",
      "Environment 0: ---- Spawning 1 workers.\n",
      "Estimated value of PI: 3.1410112\n",
      "---- Elapsed logical time (in nsec): 0\n",
      "---- Elapsed physical time (in nsec): 3,643,849,405\n"
     ]
    }
   ],
   "source": [
    "!lfc LFGPT/rag/pi/ParallelMonteCarlo.lf\n",
    "!python src-gen/LFGPT/rag/pi/ParallelMonteCarlo/ParallelMonteCarlo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import Py_Federated from '../assets/code/py/src/Federated.lf';\n"
     ]
    }
   ],
   "source": [
    "# response = query_engine.query(\"does Lingua Franca support parallelism?\")\n",
    "# print(response.response)\n",
    "# response = query_engine.query(\"How can I exploit parallelism with lingua franca?\")\n",
    "# print(response.response)\n",
    "response = query_engine.query(\"Provide a code for a minimal federated execution with lingua franca?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common errors:\n",
    "1- Main reactor cannot have outputs.\n",
    "    generated code: `output pi_estimate`\n",
    "    prompt solving: `has no outputs.`\n",
    "\n",
    "2-  No viable alternative at input.\n",
    "    generated code: `parameter num_samples = 10000000`\n",
    "    prompt solving: remove `has parameter` from prompt.\n",
    "\n",
    "3-  Syntactic error.\n",
    "    generated code: `pimport random` without preamble.\n",
    "    caused by: `import all the necessary libraries.` from prompt.\n",
    "    prompt solving: not found yet.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
